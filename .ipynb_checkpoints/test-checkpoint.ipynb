{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import os\n",
    "os.environ[\"LANG\"] = \"en_US.UTF-8\"\n",
    "import chromedriver_autoinstaller\n",
    "import skimage\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import bs4\n",
    "import requests\n",
    "from unidecode import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_list = ['Absolutno', 'Acamar', 'Achernar', 'Achird', 'Acrab', 'Acrux', 'Acubens', 'Adhafera', 'Adhara', 'Adhil', 'Ain', 'Ainalrami', 'Aladfar', 'Alasia', 'Albaldah', 'Albali', 'Albireo', 'Alchiba', 'Alcor', 'Alcyone', 'Aldebaran', 'Alderamin', 'Aldhanab', 'Aldhibah', 'Aldulfin', 'Alfirk', 'Algedi', 'Algenib', 'Algieba', 'Algol', 'Algorab', 'Alhena', 'Alioth', 'Aljanah', 'Alkaid', 'Alkalurops', 'Alkaphrah', 'Alkarab', 'Alkes', 'Almaaz', 'Almach', 'Alnair', 'Alnasl', 'Alnilam', 'Alnitak', 'Alniyat', 'Alphard', 'Alphecca', 'Alpheratz', 'Alpherg', 'Alrakis', 'Alrescha', 'Alruba', 'Alsafi', 'Alsciaukat', 'Alsephina', 'Alshain', 'Alshat', 'Altair', 'Altais', 'Alterf', 'Aludra', 'Alula Australis', 'Alula Borealis', 'Alya', 'Alzirr', 'Amadioha', 'Amansinaya', 'Anadolu', 'Ancha', 'Angetenar', 'Aniara', 'Ankaa', 'Anser', 'Antares', 'Arcalís', 'Arcturus', 'Arkab Posterior', 'Arkab Prior', 'Arneb', 'Ascella', 'Asellus Australis', 'Asellus Borealis', 'Ashlesha', 'Aspidiske', 'Asterope', 'Atakoraka', 'Athebyne', 'Atik', 'Atlas', 'Atria', 'Avior', 'Axólotl', 'Ayeyarwady', 'Azelfafage', 'Azha', 'Azmidi', 'Baekdu', \"Barnard's Star\", 'Baten Kaitos', 'Beemim', 'Beid', 'Belel', 'Bellatrix', 'Berehynia', 'Betelgeuse', 'Bharani', 'Bibhā', 'Biham', 'Bosona', 'Botein', 'Brachium', 'Bubup', 'Buna', 'Bunda', 'Bélénos', 'Canopus', 'Capella', 'Caph', 'Castor', 'Castula', 'Cebalrai', 'Ceibo', 'Celaeno', 'Cervantes', 'Chalawan', 'Chamukuy', 'Chaophraya', 'Chara', 'Chasoň', 'Chechia', 'Chertan', 'Citadelle', 'Citalá', 'Cocibolca', 'Copernicus', 'Cor Caroli', 'Cujam', 'Cursa', 'Dabih', 'Dalim', 'Deneb', 'Deneb Algedi', 'Denebola', 'Diadem', 'Dingolay', 'Diphda', 'Diya', 'Dofida', 'Dombay', 'Dschubba', 'Dubhe', 'Dziban', 'Dìwö', 'Ebla', 'Edasich', 'Electra', 'Elgafar', 'Elkurud', 'Elnath', 'Eltanin', 'Emiw', 'Enif', 'Errai', 'Fafnir', 'Fang', 'Fawaris', 'Felis', 'Felixvarela', 'Flegetonte', 'Fomalhaut', 'Formosa', 'Franz', 'Fulu', 'Fumalsamakah', 'Funi', 'Furud', 'Fuyue', 'Gacrux', 'Gakyid', 'Geminga', 'Giausar', 'Gienah', 'Ginan', 'Gloas', 'Gomeisa', 'Grumium', 'Gudja', 'Gumala', 'Guniibuu', 'Hadar', 'Haedus', 'Hamal', 'Hassaleh', 'Hatysa', 'Helvetios', 'Heze', 'Hoggar', 'Homam', 'Horna', 'Hunahpú', 'Hunor', 'Iklil', 'Illyrian', 'Imai', 'Inquill', 'Intan', 'Intercrus', 'Irena', 'Itonda', 'Izar', 'Jabbah', 'Jishui', 'Kaffaljidhma', 'Kalausi', 'Kamuy', 'Kang', 'Karaka', 'Kaus Australis', 'Kaus Borealis', 'Kaus Media', 'Kaveh', 'Keid', 'Khambalia', 'Kitalpha', 'Kochab', 'Koeia', 'Koit', 'Kornephoros', 'Kraz', 'Kurhah', 'La Superba', 'Larawag', 'Lerna', 'Lesath', 'Libertas', 'Lich', 'Liesma', 'Lilii Borea', 'Lionrock', 'Lucilinburhuc', 'Lusitânia', 'Maasym', 'Macondo', 'Mago', 'Mahasim', 'Mahsati', 'Maia', 'Malmok', 'Marfik', 'Markab', 'Markeb', 'Marsic', 'Matar', 'Mazaalai', 'Mebsuta', 'Megrez', 'Meissa', 'Mekbuda', 'Meleph', 'Menkalinan', 'Menkar', 'Menkent', 'Menkib', 'Merak', 'Merga', 'Meridiana', 'Merope', 'Mesarthim', 'Miaplacidus', 'Mimosa', 'Minchir', 'Minelauva', 'Mintaka', 'Mira', 'Mirach', 'Miram', 'Mirfak', 'Mirzam', 'Misam', 'Mizar', 'Moldoveanu', 'Montuno', 'Morava', 'Moriah', 'Mothallah', 'Mouhoun', 'Mpingo', 'Muliphein', 'Muphrid', 'Muscida', 'Musica', 'Muspelheim', 'Márohu', 'Mönch', 'Nahn', 'Naledi', 'Naos', 'Nashira', 'Natasha', 'Nekkar', 'Nembus', 'Nenque', 'Nervia', 'Nihal', 'Nikawiy', 'Nosaxa', 'Nunki', 'Nusakan', 'Nushagak', 'Nyamien', 'Násti', 'Ogma', 'Okab', 'Paikauhale', 'Parumleo', 'Peacock', 'Petra', 'Phact', 'Phecda', 'Pherkad', 'Phoenicia', 'Piautos', 'Pincoya', 'Pipirima', 'Pipoltr', 'Pleione', 'Poerava', 'Polaris', 'Polaris Australis', 'Polis', 'Pollux', 'Porrima', 'Praecipua', 'Prima Hyadum', 'Procyon', 'Propus', 'Proxima Centauri', 'Ran', 'Rana', 'Rapeto', 'Rasalas', 'Rasalgethi', 'Rasalhague', 'Rastaban', 'Regulus', 'Revati', 'Rigel', 'Rigil Kentaurus', 'Rosaliadecastro', 'Rotanev', 'Ruchbah', 'Rukbat', 'Sabik', 'Saclateni', 'Sadachbia', 'Sadalbari', 'Sadalmelik', 'Sadalsuud', 'Sadr', 'Sagarmatha', 'Saiph', 'Salm', 'Sansuna', 'Sargas', 'Sarin', 'Sceptrum', 'Scheat', 'Schedar', 'Secunda Hyadum', 'Segin', 'Seginus', 'Sham', 'Shama', 'Sharjah', 'Shaula', 'Sheliak', 'Sheratan', 'Sika', 'Sirius', 'Situla', 'Skat', 'Solaris', 'Spica', 'Sterrennacht', 'Stribor', 'Sualocin', 'Subra', 'Suhail', 'Sulafat', 'Syrma', 'Sāmaya', 'Tabit', 'Taika', 'Taiyangshou', 'Taiyi', 'Talitha', 'Tangra', 'Tania Australis', 'Tania Borealis', 'Tapecue', 'Tarazed', 'Tarf', 'Taygeta', 'Tegmine', 'Tejat', 'Terebellum', 'Tevel', 'Theemin', 'Thuban', 'Tiaki', 'Tianguan', 'Tianyi', 'Timir', 'Tislit', 'Titawin', 'Tojil', 'Toliman', 'Tonatiuh', 'Torcular', 'Tuiren', 'Tupi', 'Tupã', 'Tureis', 'Ukdah', 'Uklun', 'Unukalhai', 'Unurgunite', 'Uruk', 'Vega', 'Veritate', 'Vindemiatrix', 'Wasat', 'Wazn', 'Wezen', 'Wurren', 'Xamidimura', 'Xihe', 'Xuange', 'Yed Posterior', 'Yed Prior', 'Yildun', 'Zaniah', 'Zaurak', 'Zavijava', 'Zhang', 'Zibal', 'Zosma', 'Zubenelgenubi', 'Zubenelhakrabi', 'Zubeneschamali']\n",
    "def replace_special_characters(text):\n",
    "    # Replace special characters with their closest ASCII equivalent\n",
    "    text_ascii = unidecode(text)\n",
    "    \n",
    "    # Remove any remaining non-alphanumeric characters\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s\\'.,?!]', '', text_ascii)\n",
    "    \n",
    "    return cleaned_text\n",
    "for i in range(len(star_list)): # Replace special characters so SIMBAD can find it\n",
    "    star_list[i] = replace_special_characters(star_list[i])\n",
    "print(star_list)\n",
    "not_found = [\"Acrab\", \"Alya\", \"Dabih\", \"Geminga\", \"Lich\", \"Marsic\", \"Mazaalai\", \"Pipoltr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.exists(\"distances.txt\") and os.path.exists(\"image_urls.txt\") and os.path.exists(\"star_data.csv\") and os.path.exists(\"Star Images\")):\n",
    "    chromedriver_autoinstaller.install()\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "\n",
    "    print(\"Getting images and distances in Chrome...\")\n",
    "\n",
    "    image_urls = []\n",
    "    distances = []\n",
    "\n",
    "    already_done = [file[:-4] for file in os.listdir(\"Star Images\")]\n",
    "    already_done.sort()\n",
    "\n",
    "    for star in star_list:\n",
    "        if star in already_done or star in not_found:\n",
    "            continue\n",
    "\n",
    "        print(f\"Getting {star}...\")\n",
    "        driver.get(f\"http://simbad.u-strasbg.fr/simbad/sim-basic?Ident={star}&submit=SIMBAD+search\")\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, '/html/body/div[4]/table[3]/tbody/tr[2]/td[2]/table/tbody/tr[2]/td/div/meta')\n",
    "\n",
    "            distance = 1 / (float(driver.find_element(By.XPATH, '//*[@id=\"basic_data\"]/table/tbody/tr[8]/td[2]/b[1]/tt').text.split(\" \")[0]) / 1000)\n",
    "\n",
    "            image_url = \"https:\" + element.get_attribute('content').replace(\"reticle=true&reticleWidth=1&reticleColor=yellow&scale=true\", \"reticle=false\")\n",
    "            # https://alasky.u-strasbg.fr/cgi/simbad-thumbnails/get-thumbnail.py?name=*%20G%20Sco&size=0.35065139808548357&legend=P%2fDSS2%2fcolor&reticle=true&reticleWidth=1&reticleColor=yellow&scale=true\n",
    "\n",
    "            image_urls.append(image_url)\n",
    "            distances.append(distance)\n",
    "            img_data = requests.get(image_url).content\n",
    "            with open(f'Star Images/{star}.jpg', 'wb') as handler:\n",
    "                handler.write(img_data)\n",
    "        except NoSuchElementException:\n",
    "            print(f\"Could not find image/distance for {star}. Moving on to the next one...\")\n",
    "\n",
    "        # print(\"Image URL:\", image_url)\n",
    "        # print(\"Distance: \" + str(distance) + \" pc\")\n",
    "\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n",
    "\n",
    "    print(image_urls)\n",
    "    print(distances)\n",
    "\n",
    "    with open(\"image_urls.txt\", \"w\") as image_urls_file:\n",
    "        for i in range(len(image_urls)):\n",
    "            image_urls_file.write(image_urls[i] + (\"\\n\" if i != len(distances) - 1 else \"\"))\n",
    "\n",
    "    with open(\"distances.txt\", \"w\") as distances_file:\n",
    "        for i in range(len(distances)):\n",
    "            distances_file.write(str(distances[i]) + (\"\\n\" if i != len(distances) - 1 else \"\"))\n",
    "else:\n",
    "    print(\"Skipping this step because the files already exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_file = open(\"image_urls.txt\")\n",
    "distances_file = open(\"distances.txt\")\n",
    "\n",
    "image_urls_list = images_file.read().split(\"\\n\")\n",
    "distances_list = distances_file.read().split(\"\\n\")\n",
    "\n",
    "# combine star name with the exception of those in the not_found list, image urls, and distances into a csv file\n",
    "star_data = pandas.DataFrame({\n",
    "    \"Star Name\": [star for star in star_list if star not in not_found],\n",
    "    \"Distance (pc)\": distances_list,\n",
    "    \"Image URL\": image_urls_list\n",
    "})\n",
    "\n",
    "star_data.to_csv(\"star_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the images for image regression\n",
    "images = []\n",
    "for file in os.listdir(\"Star Images\"):\n",
    "    images.append(skimage.io.imread(f\"Star Images/{file}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Sample code to load and preprocess data\n",
    "def load_data():\n",
    "    # Load images and corresponding distances from the SIMBAD database\n",
    "    # Replace this with actual data loading code\n",
    "    images = np.random.random((1000, 128, 128, 3))  # Example: 1000 images of size 128x128 with 3 channels\n",
    "    distances = np.random.uniform(1, 10000, size=(1000,))  # Example: Random distances in parsecs\n",
    "    return images, distances\n",
    "\n",
    "# Neural network architecture\n",
    "def create_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1)  # Output layer with a single neuron for distance prediction\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Main function to train the model\n",
    "def train_model():\n",
    "    images, distances = load_data()\n",
    "    input_shape = images[0].shape\n",
    "    \n",
    "    model = create_model(input_shape)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    model.fit(images, distances, epochs=10, batch_size=32, validation_split=0.2)\n",
    "    \n",
    "    # Save the trained model\n",
    "    model.save('distance_prediction_model.h5')\n",
    "\n",
    "# Train the model\n",
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
